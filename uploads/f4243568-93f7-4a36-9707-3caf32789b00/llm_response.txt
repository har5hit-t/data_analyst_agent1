{
    "code": "import pandas as pd\nimport os\nimport io\nimport sys\n\n# Define paths\nfolder_path = 'uploads/f4243568-93f7-4a36-9707-3caf3278b00'\ndata_file_path = os.path.join(folder_path, 'data.csv')\nmetadata_file_path = os.path.join(folder_path, 'metadata.txt')\n\n# Create the folder if it doesn't exist\nos.makedirs(folder_path, exist_ok=True)\n\n# URL to scrape\nurl = \"https://en.wikipedia.org/wiki/List_of_highest-grossing_films\"\n\n# Scrape the table\n# pd.read_html returns a list of DataFrames found on the page.\n# We look for the table that contains the expected columns.\n\ntables = pd.read_html(url)\n\ndf = None\nfor table in tables:\n    # Check if the table contains key columns like 'Film', 'Worldwide gross', 'Year'\n    if 'Film' in table.columns and 'Worldwide gross' in table.columns and 'Year' in table.columns:\n        df = table\n        break\n\nif df is not None:\n    # Clean up column names by removing any bracketed text (e.g., from references)\n    df.columns = df.columns.astype(str).str.replace(r'\\[.*?\\]', '', regex=True).str.strip()\n\n    # Save the scraped data to CSV\n    df.to_csv(data_file_path, index=False)\n\n    # Generate metadata\n    with open(metadata_file_path, 'w') as f:\n        f.write(\"--- Data Description ---\\n\")\n        f.write(f\"Source URL: {url}\\n\")\n        f.write(f\"Scraped Data Path: {data_file_path}\\n\\n\")\n\n        f.write(\"--- DataFrame Info ---\\n\")\n        # Redirect stdout to capture df.info() output\n        old_stdout = sys.stdout\n        sys.stdout = captured_output = io.StringIO()\n        df.info()\n        sys.stdout = old_stdout # Restore stdout\n        f.write(captured_output.getvalue())\n        f.write(\"\\n\")\n\n        f.write(\"--- DataFrame Columns ---\\n\")\n        f.write(str(df.columns.tolist()) + \"\\n\\n\")\n\n        f.write(\"--- DataFrame Head (first 5 rows) ---\\n\")\n        f.write(df.head().to_string() + \"\\n\\n\")\n\n        f.write(\"--- Expected Answer Format ---\\n\")\n        f.write(\"The answers to the user's questions are expected to be in a JSON array of strings.\\n\")\n\nelse:\n    with open(metadata_file_path, 'w') as f:\n        f.write(\"--- Data Description ---\\n\")\n        f.write(f\"Source URL: {url}\\n\")\n        f.write(\"Could not find the expected table on the page.\\n\")\n",
    "libraries": [
        "pandas"
    ],
    "questions": [
        "How many $2 bn movies were released before 2000?",
        "Which is the earliest film that grossed over $1.5 bn?",
        "What's the correlation between the Rank and Peak?",
        "Draw a scatterplot of Rank and Peak along with a dotted red regression line through it."
    ],
    "comment": "Step-3: Getting scrap code and metadata from llm. Tries count = %d 0"
}